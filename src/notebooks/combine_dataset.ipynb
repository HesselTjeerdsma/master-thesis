{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# File mappings\n",
    "file_model_pairs = {\n",
    "    '../results/results_chatgpt.csv': 'GPTResponse',\n",
    "    '../results/results_claude.csv': 'ClaudeResponse',\n",
    "    '../results/results_llama31.csv': 'LLama31Response',\n",
    "    '../results/results_llama32.csv': 'LLama32Response',\n",
    "    '../results/results_qwen.csv': 'QwenResponse',\n",
    "    '../results/results_phi.csv': 'PhiResponse',\n",
    "    '../results/results_smol.csv': 'SmollResponse',\n",
    "    '../results/results_rf.csv': 'RFResponse',\n",
    "    '../results/results_svm.csv': 'SVMResponse',\n",
    "}\n",
    "\n",
    "# Load first file\n",
    "first_file = list(file_model_pairs.items())[0]\n",
    "combined = pd.read_csv(first_file[0], sep=None, engine='python')\n",
    "model_name = Path(first_file[0]).stem.split('_')[1]\n",
    "combined = combined[['Prompt', first_file[1]]].rename(columns={first_file[1]: f\"{model_name}_response\"})\n",
    "\n",
    "# Add other files\n",
    "for file, column in list(file_model_pairs.items())[1:]:\n",
    "    df = pd.read_csv(file, sep=None, engine='python')\n",
    "    model_name = Path(file).stem.split('_')[1]\n",
    "    df = df.rename(columns={column: f\"{model_name}_response\"})\n",
    "    combined = pd.merge(combined, df[['Prompt', f\"{model_name}_response\"]], on='Prompt', how='left')\n",
    "\n",
    "# Add metadata\n",
    "meta_df = pd.read_csv('../results/combined_model_responses_meta.ssv', sep=None, engine='python')\n",
    "combined = pd.merge(combined, meta_df[['Prompt', 'Metadata']], on='Prompt', how='left')\n",
    "\n",
    "# Save results \n",
    "output_path = Path('../results/final/final_dataset2.ssv')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "combined.to_csv(output_path, index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def extract_transaction_context(prompt):\n",
    "    \"\"\"Extract transaction context from prompt using regex pattern matching\"\"\"\n",
    "    pattern = r\"Transaction Context:\\s*A (\\d+)-year-old ([^\\s]+) who works as a ([^h][^\\s]+) has made a purchase of \\$([0-9.]+) at ([^\\s]+)\"\n",
    "    match = re.search(pattern, prompt)\n",
    "    if match:\n",
    "        return {\n",
    "            'age': int(match.group(1)),\n",
    "            'gender': match.group(2),\n",
    "            'occupation': match.group(3),\n",
    "            'amount': float(match.group(4)),\n",
    "            'merchant': match.group(5)\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def process_files(file_model_pairs):\n",
    "    \"\"\"Process multiple result files and combine them with metadata\"\"\"\n",
    "    # Load first file\n",
    "    first_file = list(file_model_pairs.items())[0]\n",
    "    combined = pd.read_csv(first_file[0], sep=None, engine='python')\n",
    "    model_name = Path(first_file[0]).stem.split('_')[1]\n",
    "    combined = combined[['Prompt', first_file[1]]].rename(\n",
    "        columns={first_file[1]: f\"{model_name}_response\"}\n",
    "    )\n",
    "    \n",
    "    # Add other files\n",
    "    for file, column in list(file_model_pairs.items())[1:]:\n",
    "        df = pd.read_csv(file, sep=None, engine='python')\n",
    "        model_name = Path(file).stem.split('_')[1]\n",
    "        df = df.rename(columns={column: f\"{model_name}_response\"})\n",
    "        combined = pd.merge(\n",
    "            combined, \n",
    "            df[['Prompt', f\"{model_name}_response\"]], \n",
    "            on='Prompt', \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    # Extract transaction contexts\n",
    "    combined['transaction_data'] = combined['Prompt'].apply(extract_transaction_context)\n",
    "    \n",
    "    # Add metadata\n",
    "    meta_df = pd.read_csv(\n",
    "        '../results/combined_model_responses_meta.ssv', \n",
    "        sep=None, \n",
    "        engine='python'\n",
    "    )\n",
    "    combined = pd.merge(\n",
    "        combined, \n",
    "        meta_df[['Prompt', 'Metadata']], \n",
    "        on='Prompt', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def save_results(combined_df, output_path='../results/final/final_dataset2.ssv'):\n",
    "    \"\"\"Save the combined results to a file\"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined_df.to_csv(output_path, index=False, sep=\";\")\n",
    "\n",
    "# File mappings\n",
    "file_model_pairs = {\n",
    "    '../results/results_chatgpt.csv': 'GPTResponse',\n",
    "    '../results/results_claude.csv': 'ClaudeResponse',\n",
    "    '../results/results_llama31.csv': 'LLama31Response',\n",
    "    '../results/results_llama32.csv': 'LLama32Response',\n",
    "    '../results/results_qwen.csv': 'QwenResponse',\n",
    "    '../results/results_phi.csv': 'PhiResponse',\n",
    "    '../results/results_smol.csv': 'SmollResponse',\n",
    "    '../results/results_rf.ssv': 'Response',\n",
    "    '../results/results_svm.ssv': 'Response',\n",
    "}\n",
    "\n",
    "combined_data = process_files(file_model_pairs)\n",
    "    \n",
    "# Save results\n",
    "save_results(combined_data,  output_path='../results/final/final_dataset2.ssv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
