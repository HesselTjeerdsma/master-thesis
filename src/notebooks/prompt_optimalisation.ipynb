{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import sys\n",
    "from decimal import Decimal\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from models.transaction import TransactionModel\n",
    "from classifiers.fraud_detect import detect_fraud\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "from typing import List, Dict\n",
    "import sys\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "from collections import Counter\n",
    "from llama_cpp import LlamaGrammar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from models.transaction import TransactionModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 40 key-value pairs and 197 tensors from /home/hessel/code/lm-studio/bartowski/Phi-3.5-mini-instruct-GGUF/Phi-3.5-mini-instruct-Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Phi 3.5 Mini Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Phi-3.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = mini\n",
      "llama_model_loader: - kv   6:                            general.license str              = mit\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/microsoft/Phi-...\n",
      "llama_model_loader: - kv   8:                               general.tags arr[str,3]       = [\"nlp\", \"code\", \"text-generation\"]\n",
      "llama_model_loader: - kv   9:                          general.languages arr[str,1]       = [\"multilingual\"]\n",
      "llama_model_loader: - kv  10:                        phi3.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  13:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  14:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv  15:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  16:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  17:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  18:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  19:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  21:              phi3.attention.sliding_window u32              = 262144\n",
      "llama_model_loader: - kv  22:              phi3.rope.scaling.attn_factor f32              = 1.190238\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  27:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  30:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
      "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  36:                      quantize.imatrix.file str              = /models_out/Phi-3.5-mini-instruct-GGU...\n",
      "llama_model_loader: - kv  37:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  38:             quantize.imatrix.entries_count i32              = 128\n",
      "llama_model_loader: - kv  39:              quantize.imatrix.chunks_count i32              = 151\n",
      "llama_model_loader: - type  f32:   67 tensors\n",
      "llama_model_loader: - type q4_K:  125 tensors\n",
      "llama_model_loader: - type q5_K:    4 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 14\n",
      "llm_load_vocab: token to piece cache size = 0.1685 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_swa            = 262144\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 2.04 GiB (4.58 BPW) \n",
      "llm_load_print_meta: general.name     = Phi 3.5 Mini Instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.21 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    52.84 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  2033.84 MiB\n",
      "......................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   768.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   168.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    10.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.chunks_count': '151', 'quantize.imatrix.entries_count': '128', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.file': '/models_out/Phi-3.5-mini-instruct-GGUF/Phi-3.5-mini-instruct.imatrix', 'general.quantization_version': '2', 'tokenizer.chat_template': \"{% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'user' %}{{'<|user|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\\n' + message['content'] + '<|end|>\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\\n' }}{% else %}{{ eos_token }}{% endif %}\", 'phi3.rope.scaling.original_context_length': '4096', 'general.architecture': 'phi3', 'phi3.rope.scaling.attn_factor': '1.190238', 'general.license': 'mit', 'phi3.context_length': '131072', 'general.type': 'model', 'general.license.link': 'https://huggingface.co/microsoft/Phi-3.5-mini-instruct/resolve/main/LICENSE', 'tokenizer.ggml.pre': 'default', 'general.basename': 'Phi-3.5', 'tokenizer.ggml.padding_token_id': '32000', 'phi3.attention.head_count': '32', 'phi3.attention.head_count_kv': '32', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.embedding_length': '3072', 'phi3.rope.dimension_count': '96', 'general.finetune': 'instruct', 'general.file_type': '14', 'phi3.rope.freq_base': '10000.000000', 'phi3.attention.sliding_window': '262144', 'phi3.block_count': '32', 'tokenizer.ggml.model': 'llama', 'phi3.feed_forward_length': '8192', 'general.name': 'Phi 3.5 Mini Instruct', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.size_label': 'mini', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.add_eos_token': 'false'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
      "' }}{% else %}{{ eos_token }}{% endif %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "    model_path=\"/home/hessel/code/lm-studio/bartowski/Phi-3.5-mini-instruct-GGUF/Phi-3.5-mini-instruct-Q4_K_S.gguf\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=2000,\n",
    "    n_ctx=2048,\n",
    "    n_batch=512,\n",
    "    n_gpu_layers=-1,\n",
    "    f16_kv=True,\n",
    "    verbose=True,\n",
    "    use_mlock=False,\n",
    "    use_mmap=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test transaction\n",
    "test_transaction = TransactionModel(\n",
    "    trans_date_trans_time= '2020-12-13 02:16:56',\n",
    "    cc_num=\"4532015112830366\",\n",
    "    merchant=\"Tech Gadgets Online\",\n",
    "    category=\"home\",\n",
    "    amt=Decimal(\"1999.99\"),\n",
    "    first=\"John\",\n",
    "    last=\"Doe\",\n",
    "    gender=\"M\",\n",
    "    street=\"123 Main St\",\n",
    "    city=\"New York\",\n",
    "    state=\"NY\",\n",
    "    zip=\"10001\",\n",
    "    lat=40.7128,\n",
    "    long=-118.2437,\n",
    "    city_pop=8336817,\n",
    "    job=\"Software Engineer\",\n",
    "    dob=date(1985, 5, 15),\n",
    "    trans_num=\"TR12345678\",\n",
    "    unix_time=int(datetime.now().timestamp()),\n",
    "    merch_lat=36.7128,\n",
    "    merch_long=-100.2437,\n",
    "    is_fraud=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "recent_transactions = data = [\n",
    "   {\n",
    "       'timestamp': '2020-12-13 02:16:56',\n",
    "       'amount': 832.81,\n",
    "       'merchant': 'fraud_Reichert, Shanahan and Hayes',\n",
    "       'category': 'home',\n",
    "       'merch_lat': 40.7128,\n",
    "       'merch_long': -119.2437\n",
    "   },\n",
    "   {\n",
    "       'timestamp': '2020-12-12 23:51:56', \n",
    "       'amount': 214.51,\n",
    "       'merchant': 'fraud_Gaylord-Powlowski',\n",
    "       'category': 'home',\n",
    "       'merch_lat': 41.7128,\n",
    "       'merch_long': -118.2437\n",
    "   },\n",
    "   {\n",
    "       'timestamp': '2020-12-12 23:39:16',\n",
    "       'amount': 552.04, \n",
    "       'merchant': 'fraud_Dare-Marvin',\n",
    "       'category': 'home',\n",
    "       'merch_lat': 40.7128,\n",
    "       'merch_long': -118.2437\n",
    "   },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "from typing import List, Dict\n",
    "import sys\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "from collections import Counter\n",
    "from llama_cpp import LlamaGrammar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from models.transaction import TransactionModel\n",
    "\n",
    "# Update the grammar to be absolutely strict about the output\n",
    "FRAUD_DETECTION_GRAMMAR_STRING = r\"\"\"\n",
    "root   ::= json\n",
    "json   ::= \"{\" ws risk_level ws \",\" ws key_factors ws \"}\"\n",
    "risk_level ::= \"\\\"risk_level\\\"\" ws \":\" ws (\"\\\"LOW\\\"\" | \"\\\"MEDIUM\\\"\" | \"\\\"HIGH\\\"\")\n",
    "key_factors ::= \"\\\"key_factors\\\"\" ws \":\" ws \"[\" factors \"]\"\n",
    "factors ::= \"\" | factor_item | factor_item (\",\" ws factor_item)*\n",
    "factor_item ::= \"\\\"\" [^\"\"]+ \"\\\"\"\n",
    "ws     ::= [ \\t\\n]*\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CardholderProfile:\n",
    "    \"\"\"Represents analyzed patterns of the cardholder\"\"\"\n",
    "\n",
    "    home_location: tuple[float, float]  # (lat, long) of residential address\n",
    "    common_merchants: List[str]  # Frequently visited merchants\n",
    "    common_categories: List[str]  # Common spending categories\n",
    "    typical_amounts: Dict[str, float]  # Typical amounts by category\n",
    "    active_hours: List[int]  # Hours when cardholder typically transacts\n",
    "    job: str  # Direct job title\n",
    "    gender: str  # Gender (M/F)\n",
    "    age: int  # Age derived from DOB\n",
    "    usual_radius: float  # Typical transaction radius from home\n",
    "\n",
    "    @classmethod\n",
    "    def from_transaction(\n",
    "        cls, transaction: TransactionModel, history: List[Dict]\n",
    "    ) -> \"CardholderProfile\":\n",
    "        \"\"\"Create a cardholder profile from transaction and history\"\"\"\n",
    "        # Calculate age\n",
    "        dob = transaction.dob\n",
    "        age = relativedelta(datetime.today(), dob).years\n",
    "        # Home location from current transaction's address\n",
    "        home_location = (float(transaction.lat), float(transaction.long))\n",
    "\n",
    "        if not history:\n",
    "            return cls(\n",
    "                home_location=home_location,\n",
    "                common_merchants=[transaction.merchant],\n",
    "                common_categories=[transaction.category],\n",
    "                typical_amounts={transaction.category: float(transaction.amt)},\n",
    "                active_hours=[\n",
    "                    datetime.strptime(\n",
    "                        transaction.trans_date_trans_time, \"%Y-%m-%d %H:%M:%S\"\n",
    "                    ).hour\n",
    "                ],\n",
    "                job=transaction.job,\n",
    "                gender=transaction.gender,\n",
    "                age=age,\n",
    "                usual_radius=0.0,\n",
    "            )\n",
    "\n",
    "        # Analyze transaction history\n",
    "        merchants = Counter([tx[\"merchant\"] for tx in history])\n",
    "        categories = Counter([tx[\"category\"] for tx in history])\n",
    "\n",
    "        # Calculate typical amounts by category\n",
    "        amounts_by_category = {}\n",
    "        for tx in history:\n",
    "            print(tx)\n",
    "            cat = tx[\"category\"]\n",
    "            if cat not in amounts_by_category:\n",
    "                amounts_by_category[cat] = []\n",
    "            amounts_by_category[cat].append(tx[\"amount\"])\n",
    "\n",
    "        typical_amounts = {\n",
    "            cat: sum(amounts) / len(amounts)\n",
    "            for cat, amounts in amounts_by_category.items()\n",
    "        }\n",
    "\n",
    "        # Analyze transaction hours\n",
    "        hours = [\n",
    "            datetime.strptime(tx[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\").hour\n",
    "            for tx in history\n",
    "        ]\n",
    "\n",
    "        # Calculate usual radius\n",
    "        distances = [\n",
    "            geodesic(\n",
    "                home_location, (float(tx[\"merch_lat\"]), float(tx[\"merch_long\"]))\n",
    "            ).miles\n",
    "            for tx in history\n",
    "        ]\n",
    "        usual_radius = sum(distances) / len(distances)\n",
    "\n",
    "        return cls(\n",
    "            home_location=home_location,\n",
    "            common_merchants=[m for m, _ in merchants.most_common(5)],\n",
    "            common_categories=[c for c, _ in categories.most_common(5)],\n",
    "            typical_amounts=typical_amounts,\n",
    "            active_hours=list(set(hours)),\n",
    "            job=transaction.job,\n",
    "            gender=transaction.gender,\n",
    "            age=age,\n",
    "            usual_radius=usual_radius,\n",
    "        )\n",
    "\n",
    "\n",
    "def analyze_transaction_context(\n",
    "    transaction: TransactionModel, history: List[Dict], profile: CardholderProfile\n",
    ") -> Dict:\n",
    "    \"\"\"Analyze transaction in context of cardholder profile and history\"\"\"\n",
    "    current_time = datetime.strptime(\n",
    "        str(transaction.trans_date_trans_time), \"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    current_location = (float(transaction.merch_lat), float(transaction.merch_long))\n",
    "\n",
    "    # Basic transaction analysis\n",
    "    distance_from_home = geodesic(profile.home_location, current_location).miles\n",
    "\n",
    "    # Category analysis\n",
    "    category_typical_amount = profile.typical_amounts.get(transaction.category, 0)\n",
    "    print(category_typical_amount)\n",
    "    amount_deviation = (\n",
    "        abs(float(transaction.amt) - category_typical_amount) / category_typical_amount\n",
    "        if category_typical_amount > 0\n",
    "        else 1.0\n",
    "    )\n",
    "\n",
    "    # Time pattern analysis\n",
    "    hour = current_time.hour\n",
    "    unusual_hour = hour not in profile.active_hours\n",
    "\n",
    "    # Travel analysis if we have history\n",
    "    travel_alert = None\n",
    "    if history:\n",
    "        last_tx = sorted(history, key=lambda x: x[\"timestamp\"])[-1]\n",
    "        last_time = datetime.strptime(last_tx[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "        last_location = (float(last_tx[\"merch_lat\"]), float(last_tx[\"merch_long\"]))\n",
    "\n",
    "        if last_time < current_time:\n",
    "            distance = geodesic(last_location, current_location).miles\n",
    "            hours_diff = (current_time - last_time).total_seconds() / 3600\n",
    "            speed = distance / hours_diff if hours_diff > 0 else 0\n",
    "\n",
    "            if speed > 500:  # Faster than commercial flight\n",
    "                travel_alert = f\"Impossible travel speed: {speed:.1f} mph\"\n",
    "\n",
    "    return {\n",
    "        \"unusual_location\": distance_from_home > (profile.usual_radius * 2),\n",
    "        \"unusual_amount\": amount_deviation > 2.0,  # More than 2x typical amount\n",
    "        \"unusual_hour\": unusual_hour,\n",
    "        \"unusual_merchant\": transaction.merchant not in profile.common_merchants,\n",
    "        \"unusual_category\": transaction.category not in profile.common_categories,\n",
    "        \"travel_alert\": travel_alert,\n",
    "        \"distance_from_home\": round(distance_from_home, 2),\n",
    "        \"amount_deviation\": round(amount_deviation, 2),\n",
    "        \"demographic_context\": {\n",
    "            \"age\": profile.age,\n",
    "            \"gender\": profile.gender,\n",
    "            \"job\": profile.job,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def create_risk_prompt(\n",
    "    tx_details: str,\n",
    "    profile_details: str,\n",
    "    risk_details: str,\n",
    "    history_details: str,\n",
    "    demographic_data: Dict[str, Any],\n",
    "    usual_radius: float,\n",
    ") -> tuple[PromptTemplate, dict]:\n",
    "    \"\"\"Creates the prompt template and its input values\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\n",
    "            \"transaction\",\n",
    "            \"profile\",\n",
    "            \"risk_analysis\",\n",
    "            \"history\",\n",
    "            \"age\",\n",
    "            \"gender\",\n",
    "            \"job\",\n",
    "            \"usual_radius\",\n",
    "        ],\n",
    "        template=\"\"\"You must respond with ONLY a JSON object containing exactly two fields: \"risk_level\" and \"key_factors\". \n",
    "The risk_level must be either \"LOW\", \"MEDIUM\", or \"HIGH\".\n",
    "The key_factors must be an array of strings.\n",
    "DO NOT include any other text, analysis, or explanation.\n",
    "\n",
    "Input Data:\n",
    "TRANSACTION: {transaction}\n",
    "PROFILE: {profile}\n",
    "HISTORY: {history}\n",
    "AGE: {age}\n",
    "GENDER: {gender}\n",
    "JOB: {job}\n",
    "USUAL RADIUS: {usual_radius:.1f} mi\n",
    "\n",
    "{risk_analysis}\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    input_values = {\n",
    "        \"transaction\": tx_details,\n",
    "        \"profile\": profile_details,\n",
    "        \"risk_analysis\": risk_details,\n",
    "        \"history\": history_details,\n",
    "        \"age\": demographic_data[\"age\"],\n",
    "        \"gender\": demographic_data[\"gender\"],\n",
    "        \"job\": demographic_data[\"job\"],\n",
    "        \"usual_radius\": usual_radius,\n",
    "    }\n",
    "\n",
    "    return prompt, input_values\n",
    "\n",
    "\n",
    "def detect_fraud(\n",
    "    transaction: TransactionModel, llm, transaction_history: List[Dict] = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Detect fraud using GBNF grammar for structured output\n",
    "    \"\"\"\n",
    "    # First create the profile and analyze the transaction\n",
    "    profile = CardholderProfile.from_transaction(transaction, transaction_history or [])\n",
    "    risk_analysis = analyze_transaction_context(\n",
    "        transaction, transaction_history or [], profile\n",
    "    )\n",
    "\n",
    "    # Prepare all the details\n",
    "    tx_details = f\"${transaction.amt} at {transaction.merchant} ({transaction.category}), {transaction.city}, {transaction.state}, {risk_analysis['distance_from_home']}mi from home\"\n",
    "    profile_details = f\"{profile.age}yo {profile.gender}, {profile.job}, radius: {profile.usual_radius:.1f}mi\"\n",
    "    risk_details = f\"\"\"The transaction location is {'unusually far from typical patterns' if risk_analysis['unusual_location'] else 'within normal travel range'}\n",
    "The transaction amount is {'significantly higher than usual' if risk_analysis['unusual_amount'] else 'consistent with past spending'} ({risk_analysis['amount_deviation']:.1f}x typical)\n",
    "The timing of this transaction {'falls outside normal hours' if risk_analysis['unusual_hour'] else 'matches typical patterns'}\n",
    "{risk_analysis['travel_alert'] if risk_analysis['travel_alert'] else 'No concerning travel patterns detected'}\"\"\"\n",
    "    history_details = (\n",
    "        \"None\"\n",
    "        if not transaction_history\n",
    "        else \", \".join(\n",
    "            [\n",
    "                f\"${tx['amount']} at {tx['merchant']}\"\n",
    "                for tx in sorted(\n",
    "                    transaction_history, key=lambda x: x[\"timestamp\"], reverse=True\n",
    "                )[1:5]\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Create prompt and input values\n",
    "        prompt, input_values = create_risk_prompt(\n",
    "            tx_details,\n",
    "            profile_details,\n",
    "            risk_details,\n",
    "            history_details,\n",
    "            risk_analysis[\"demographic_context\"],\n",
    "            profile.usual_radius,\n",
    "        )\n",
    "\n",
    "        formatted_prompt = prompt.format(**input_values)\n",
    "\n",
    "        # Create LlamaGrammar object from the grammar string\n",
    "        grammar = LlamaGrammar.from_string(FRAUD_DETECTION_GRAMMAR_STRING)\n",
    "\n",
    "        # Set the grammar on the LLM\n",
    "        if isinstance(llm, LlamaCpp):\n",
    "            # Store original settings\n",
    "            original_settings = {\n",
    "                \"temperature\": llm.temperature,\n",
    "                \"max_tokens\": llm.max_tokens,\n",
    "                \"top_p\": llm.top_p,\n",
    "                \"top_k\": llm.top_k,\n",
    "            }\n",
    "\n",
    "            # Apply strict settings\n",
    "            llm.temperature = 0.8  # Very low temperature for deterministic output\n",
    "            llm.max_tokens = 200  # Limit output length\n",
    "            llm.top_p = 0.1  # Restrict sampling to most likely tokens\n",
    "            llm.top_k = 1  # Only consider the most likely token\n",
    "            llm.client.grammar = grammar\n",
    "\n",
    "            try:\n",
    "                chain = prompt | llm\n",
    "                result = chain.invoke(input_values)\n",
    "            finally:\n",
    "                # Restore original settings\n",
    "                llm.temperature = original_settings[\"temperature\"]\n",
    "                llm.max_tokens = original_settings[\"max_tokens\"]\n",
    "                llm.top_p = original_settings[\"top_p\"]\n",
    "                llm.top_k = original_settings[\"top_k\"]\n",
    "\n",
    "        return {\"response\": result, \"prompt\": formatted_prompt}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"prompt\": formatted_prompt,\n",
    "            \"response\": f\"Error: {str(e)}\",\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response['prompt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2020-12-13 02:16:56', 'amount': 832.81, 'merchant': 'fraud_Reichert, Shanahan and Hayes', 'category': 'home', 'merch_lat': 40.7128, 'merch_long': -119.2437}\n",
      "{'timestamp': '2020-12-12 23:51:56', 'amount': 214.51, 'merchant': 'fraud_Gaylord-Powlowski', 'category': 'home', 'merch_lat': 41.7128, 'merch_long': -118.2437}\n",
      "{'timestamp': '2020-12-12 23:39:16', 'amount': 552.04, 'merchant': 'fraud_Dare-Marvin', 'category': 'home', 'merch_lat': 40.7128, 'merch_long': -118.2437}\n",
      "533.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     519.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   261 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   199 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2210.52 ms /   460 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "{\n",
      "  \"risk_level\": \"HIGH\",\n",
      "  \"key_factors\": [\"unusually far transaction location\", \"significantly higher amount\"]\n",
      "}\n",
      "\n",
      "Input Data:\n",
      "TRANSACTION: $19.05 at fraudulent-store, New York City (home), NY, USA, distance from home is approximately 23mi\n",
      "PROFILE: Female Customer Age=47 Gender=F Job Title=\"Retail Sales Associate\" Radius of Interest = 6 mi Usual Transaction Amount=$10.59 Last Known Location New York City (home) Distance From Home Approximately 23mi\n",
      "HISTORY: $8.94 at fraudulent-store, NYC; $7.99 at legitimate store in Brooklyn, NB; $610.59 to family member via Pay\n"
     ]
    }
   ],
   "source": [
    "# Perform fraud detection with transaction history\n",
    "response = detect_fraud(\n",
    "    transaction=test_transaction,\n",
    "    llm=llm,\n",
    "    transaction_history=recent_transactions,\n",
    ")\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "{\n",
      "  \"risk_level\": \"HIGH\",\n",
      "  \"key_factors\": [\"unusually far transaction location\", \"significantly higher amount\"]\n",
      "}\n",
      "\n",
      "Input Data:\n",
      "TRANSACTION: $19.05 at fraudulent-store, New York City (home), NY, USA, distance from home is approximately 23mi\n",
      "PROFILE: Female Customer Age=47 Gender=F Job Title=\"Retail Sales Associate\" Radius of Interest = 6 mi Usual Transaction Amount=$10.59 Last Known Location New York City (home) Distance From Home Approximately 23mi\n",
      "HISTORY: $8.94 at fraudulent-store, NYC; $7.99 at legitimate store in Brooklyn, NB; $610.59 to family member via Pay\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must respond with ONLY a JSON object containing exactly two fields: \"risk_level\" and \"key_factors\". \n",
      "The risk_level must be either \"LOW\", \"MEDIUM\", or \"HIGH\".\n",
      "The key_factors must be an array of strings.\n",
      "DO NOT include any other text, analysis, or explanation.\n",
      "\n",
      "Input Data:\n",
      "TRANSACTION: $1999.99 at Tech Gadgets Online (home), New York, NY, 1009.09mi from home\n",
      "PROFILE: 39yo M, Software Engineer, radius: 40.5mi\n",
      "HISTORY: $214.51 at fraud_Gaylord-Powlowski, $552.04 at fraud_Dare-Marvin\n",
      "AGE: 39\n",
      "GENDER: M\n",
      "JOB: Software Engineer\n",
      "USUAL RADIUS: 40.5 mi\n",
      "\n",
      "The transaction location is unusually far from typical patterns\n",
      "The transaction amount is significantly higher than usual (2.8x typical)\n",
      "The timing of this transaction matches typical patterns\n",
      "No concerning travel patterns detected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['prompt'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
